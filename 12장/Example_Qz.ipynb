{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\python312\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\python312\\lib\\site-packages (from konlpy) (1.5.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\python312\\lib\\site-packages (from konlpy) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\python312\\lib\\site-packages (from konlpy) (2.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('나', 'Noun'), ('는', 'Josa'), ('자연어', 'Noun'), ('처리', 'Noun'), ('를', 'Josa'), ('배운다', 'Verb')]\n",
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "# 1. 다음 코드의 실행결과를 구하세요.\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "text = \"나는 자연어 처리를 배운다\"\n",
    "tagged_text = okt.pos(text)\n",
    "print(tagged_text)\n",
    "tokenized_text = okt.morphs(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화: 50737회\n",
      "정말: 9645회\n",
      "진짜: 8343회\n",
      "이: 8001회\n",
      "점: 7930회\n"
     ]
    }
   ],
   "source": [
    "# 2. 다음 실행결과를 확인하고, 빈 곳을 채워 코드를 완성하세요.\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 가사 불러오기\n",
    "with open(\"../resources/12장/ratings_train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics = f.read()\n",
    "\n",
    "# 텍스트 테이터 전처리\n",
    "lyrics = lyrics.replace(\"\\n\", \" \")  # 개행 문자 제거\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 품사 태깅과 형태소 분석 수행\n",
    "pos = okt.pos(lyrics)\n",
    "nouns = [word for word, tag in pos if tag == \"Noun\"]  # 명사만 추출\n",
    "\n",
    "# 가장 많이 언급된 명사 5개 출력\n",
    "top_nouns = Counter(nouns).most_common(5)\n",
    "for noun, freq in top_nouns:\n",
    "    print(f\"{noun}: {freq}회\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화: 4회\n",
      "연기: 3회\n",
      "재미: 2회\n",
      "평점: 2회\n",
      "반개: 2회\n"
     ]
    }
   ],
   "source": [
    "# 3. 불용어가 다음과 같을 때 해당 단어를 제외하고 빈도수가 높은 5개의 단어를 출력하세요.\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 노래 가사\n",
    "# 가사 불러오기\n",
    "with open(\"../resources/12장/ratings_train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics = f.read()\n",
    "\n",
    "# 텍스트 테이터 전처리\n",
    "lyrics = lyrics.replace(\"\\n\", \" \")  # 개행 문자 제거\n",
    "stopword = [\"순\", \"수만\", \"안\", \"노\", \"땐\", \"줄\", \"가지\", \"것들이\", \"해\"]\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 품사 태깅과 형태소 분석 수행\n",
    "pos = okt.pos(lyrics[0:500])\n",
    "nouns = [\n",
    "    word for word, tag in pos if tag not in stopword and tag == \"Noun\"\n",
    "]  # 명사만 추출\n",
    "\n",
    "# 가장 많이 언급된 명사 5개 출력\n",
    "top_nouns = Counter(nouns).most_common(5)\n",
    "for noun, freq in top_nouns:\n",
    "    print(f\"{noun}: {freq}회\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('영화', 134),\n",
       " ('좋아하는', 99),\n",
       " ('감동', 99),\n",
       " ('모든', 99),\n",
       " ('분', 66),\n",
       " ('아이', 66),\n",
       " ('사람', 66),\n",
       " ('진짜', 48),\n",
       " ('단조로운', 34),\n",
       " ('스토리', 34),\n",
       " ('긴장감', 34),\n",
       " ('있', 34),\n",
       " ('납치', 34),\n",
       " ('범', 34),\n",
       " ('대가리', 34),\n",
       " ('지네', 34),\n",
       " ('집중', 34),\n",
       " ('안되네', 34),\n",
       " ('싱크홀', 33),\n",
       " ('별로', 33)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 빈 곳을 채워 연습3 텍스트 파일을 읽어와 상위 20개의 명사를 추출하세요.\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "temp_list = []\n",
    "df = pd.read_csv(\"../resources/12장/comment_rank.csv\")\n",
    "\n",
    "# 텍스트 테이터 전처리\n",
    "df[\"comment\"] = df[\"comment\"].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \"\", regex=True)\n",
    "df.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 품사 태깅과 형태소 분석 수행\n",
    "for sentence in df[\"comment\"][0:300]:\n",
    "    s_list = okt.pos(sentence)\n",
    "    for word, tag in s_list:\n",
    "        if tag in [\"Noun\", \"Adjective\"]:\n",
    "            temp_list.append(word)\n",
    "\n",
    "tag = Counter(temp_list).most_common(20)\n",
    "tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
